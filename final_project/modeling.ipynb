{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas  0.25.1\n",
      "numpy  1.16.5\n",
      "sklearn 0.21.3\n"
     ]
    }
   ],
   "source": [
    "# create our machine learning models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "print('pandas ', pd.__version__)\n",
    "print('numpy ', np.__version__)\n",
    "print('sklearn', sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2464, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2459    1\n",
      "2460    1\n",
      "2461    1\n",
      "2462    1\n",
      "2463    1\n",
      "Name: Attrition, Length: 2464, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "y = data['Attrition']\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Age  DailyRate  DistanceFromHome  EmployeeNumber  \\\n",
      "0     0.446350   0.742527         -1.010909       -1.701283   \n",
      "1     1.322365  -1.297775         -0.147150       -1.699621   \n",
      "2     0.008343   1.414363         -0.887515       -1.696298   \n",
      "3    -0.429664   1.461466         -0.764121       -1.694636   \n",
      "4    -1.086676  -0.524295         -0.887515       -1.691313   \n",
      "...        ...        ...               ...             ...   \n",
      "2459 -0.753371  -0.098876         -0.887515        0.296628   \n",
      "2460 -1.345354   0.607110          0.829274        1.298087   \n",
      "2461 -1.850294   0.735002          0.219772       -0.004952   \n",
      "2462 -1.045215  -0.495451          0.393148        0.776320   \n",
      "2463 -1.505161  -0.355432          0.782607       -1.048411   \n",
      "\n",
      "      EnvironmentSatisfaction  JobInvolvement  JobLevel   JobRole  \\\n",
      "0                   -0.660531        0.379672 -0.057788  1.032716   \n",
      "1                    0.254625       -1.026167 -0.057788  0.626374   \n",
      "2                    1.169781       -1.026167 -0.961486 -0.998992   \n",
      "3                    1.169781        0.379672 -0.961486  0.626374   \n",
      "4                   -1.575686        0.379672 -0.961486 -0.998992   \n",
      "...                       ...             ...       ...       ...   \n",
      "2459                 0.254625       -0.578089 -0.961486  1.180034   \n",
      "2460                 0.858097        0.379672 -0.961486 -1.266942   \n",
      "2461                 1.169781       -1.026167 -0.961486  0.612054   \n",
      "2462                 0.501926       -0.000226  0.357501 -1.592065   \n",
      "2463                 0.685010       -1.770859 -0.961486 -0.998992   \n",
      "\n",
      "      JobSatisfaction  MaritalStatus  ...  NumCompaniesWorked  OverTime  \\\n",
      "0            1.153254       1.236820  ...            2.125136  1.591746   \n",
      "1           -0.660853      -0.133282  ...           -0.678049 -0.628241   \n",
      "2            0.246200       1.236820  ...            1.324226  1.591746   \n",
      "3            0.246200      -0.133282  ...           -0.678049  1.591746   \n",
      "4           -0.660853      -0.133282  ...            2.525591 -0.628241   \n",
      "...               ...            ...  ...                 ...       ...   \n",
      "2459         0.864152       1.236820  ...            1.597045 -0.628241   \n",
      "2460        -0.969778      -0.133282  ...           -0.942117  1.591746   \n",
      "2461        -1.551924       1.236820  ...           -0.678049  1.591746   \n",
      "2462         0.908142       1.236820  ...           -0.970290  1.591746   \n",
      "2463         1.153254       1.236820  ...           -0.678049  1.591746   \n",
      "\n",
      "      RelationshipSatisfaction  StockOptionLevel  TotalWorkingYears  \\\n",
      "0                    -1.584178         -0.932014          -0.421642   \n",
      "1                     1.191438          0.241988          -0.164511   \n",
      "2                    -0.658973         -0.932014          -0.550208   \n",
      "3                     0.266233         -0.932014          -0.421642   \n",
      "4                     1.191438          0.241988          -0.678774   \n",
      "...                        ...               ...                ...   \n",
      "2459                  0.561120         -0.932014          -0.982516   \n",
      "2460                  0.266233         -0.932014          -0.897708   \n",
      "2461                 -1.584178         -0.932014          -1.317070   \n",
      "2462                 -1.584178         -0.932014          -0.432045   \n",
      "2463                 -0.658973         -0.932014          -1.321601   \n",
      "\n",
      "      TrainingTimesLastYear  YearsAtCompany  YearsInCurrentRole  \\\n",
      "0                 -2.171982       -0.164613           -0.063296   \n",
      "1                  0.155707        0.488508            0.764998   \n",
      "2                  0.155707       -1.144294           -1.167687   \n",
      "3                  0.155707        0.161947            0.764998   \n",
      "4                  0.155707       -0.817734           -0.615492   \n",
      "...                     ...             ...                 ...   \n",
      "2459               0.155707       -0.928972           -0.991688   \n",
      "2460               0.948472       -0.550333           -0.985623   \n",
      "2461              -0.620189       -0.975260           -1.157957   \n",
      "2462              -1.186416        0.029578            0.541169   \n",
      "2463               0.885494       -0.981014           -1.167687   \n",
      "\n",
      "      YearsSinceLastPromotion  YearsWithCurrManager  \n",
      "0                   -0.679146              0.245834  \n",
      "1                   -0.368715              0.806541  \n",
      "2                   -0.679146             -1.155935  \n",
      "3                    0.252146             -1.155935  \n",
      "4                   -0.058285             -0.595227  \n",
      "...                       ...                   ...  \n",
      "2459                -0.481261             -1.066579  \n",
      "2460                -0.474442             -0.416451  \n",
      "2461                -0.676411             -1.150995  \n",
      "2462                 0.990544              0.427744  \n",
      "2463                -0.533155             -1.155935  \n",
      "\n",
      "[2464 rows x 22 columns]\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns =['Attrition'])\n",
    "print(X)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "(2464,)\n",
      "[[ 0.4463504   0.74252653 -1.01090934 ... -0.0632959  -0.67914568\n",
      "   0.24583399]\n",
      " [ 1.32236521 -1.2977746  -0.14714972 ...  0.76499762 -0.36871529\n",
      "   0.80654148]\n",
      " [ 0.008343    1.41436324 -0.88751511 ... -1.16768726 -0.67914568\n",
      "  -1.15593471]\n",
      " ...\n",
      " [-1.85029423  0.73500173  0.21977154 ... -1.15795719 -0.67641068\n",
      "  -1.15099468]\n",
      " [-1.04521495 -0.49545128  0.39314783 ...  0.5411691   0.99054423\n",
      "   0.42774361]\n",
      " [-1.50516057 -0.35543202  0.78260728 ... -1.16768726 -0.53315458\n",
      "  -1.15593471]]\n",
      "<class 'numpy.ndarray'>\n",
      "(2464, 22)\n"
     ]
    }
   ],
   "source": [
    "# convert X and y to numpy arrays\n",
    "\n",
    "y = np.asarray(y)\n",
    "X = np.asarray(X)\n",
    "print(y)\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "\n",
    "print(X)\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 49.18815663801337  percent of training data is in class 1\n",
      "len y_train:  2094\n",
      "len y_test:  370\n",
      "\n",
      " 54.59459459459459  percent of test data is in class 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 30\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,random_state=random_seed)\n",
    "\n",
    "numerator = y_train[y_train == 1].sum()\n",
    "denominator = len(y_train)\n",
    "print(\"\\n\", numerator/denominator * 100, \" percent of training data is in class 1\")\n",
    "print('len y_train: ', len(y_train))\n",
    "print('len y_test: ', len(y_test))\n",
    "\n",
    "numerator2 = y_test[y_test == 1].sum()\n",
    "denominator2 = len(y_test)\n",
    "print('\\n', numerator2/denominator2 * 100, ' percent of test data is in class 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy(y_test, y_pred):\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i]==1 and y_pred[i]== 1:\n",
    "                tp +=1\n",
    "        elif y_test[i]==0 and y_pred[i]== 0:\n",
    "                tn +=1\n",
    "        elif y_test[i]==0 and y_pred[i]== 1:\n",
    "                fp +=1\n",
    "        else:\n",
    "            fn +=1\n",
    "    \n",
    "    return 0.5 * ((tp / (tp + fn)) + (tn / (tn + fp))),[tp,tn,fp,fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.9135135135135135\n",
      "balanced accuracy:  0.9057637906647807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Train logistic regression model (with default regularization) for binary classification\n",
    "knn_model = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data and print the test accuracy\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "knn_test_accuracy = metrics.accuracy_score(y_test, y_pred_knn)\n",
    "print('\\nTest accuracy: '+str(knn_test_accuracy))\n",
    "\n",
    "knn_balanced_accuracy, knn_eval_metrics=balanced_accuracy(y_test,y_pred_knn)\n",
    "print(\"balanced accuracy: \", knn_balanced_accuracy)\n",
    "\n",
    "model_accs = {\n",
    "    'knn': [knn_test_accuracy,knn_balanced_accuracy,knn_eval_metrics]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8513513513513513\n",
      "balanced accuracy: 0.8473302687411599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=8, \n",
    "                              random_state=2)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "tree_test_accuracy = metrics.accuracy_score(y_test, y_pred_tree)\n",
    "print(\"Test accuracy: \"+str(tree_test_accuracy))\n",
    "\n",
    "tree_balanced_accuracy, tree_eval_metrics=balanced_accuracy(y_test,y_pred_tree)\n",
    "print(\"balanced accuracy:\", tree_balanced_accuracy)\n",
    "\n",
    "model_accs['decision tree'] = [tree_test_accuracy,tree_balanced_accuracy,tree_eval_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plot_tree(tree, \n",
    "          filled=True, \n",
    "          rounded=True,\n",
    "          class_names=['Yes', \n",
    "                       'No']) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linds\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9054054054054054\n",
      "balanced accuracy: 0.9033474776049033\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "svm_test_accuracy = metrics.accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy:\",svm_test_accuracy)\n",
    "\n",
    "svm_balanced_accuracy, svm_eval_metrics=balanced_accuracy(y_test,y_pred_svm)\n",
    "print(\"balanced accuracy:\", svm_balanced_accuracy)\n",
    "\n",
    "model_accs['svm'] = [svm_test_accuracy,svm_balanced_accuracy,svm_eval_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7783783783783784\n",
      "balanced accuracy: 0.775489156058463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(penalty='l2', random_state=0, solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "lr_test_accuracy = metrics.accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy: \", lr_test_accuracy)\n",
    "\n",
    "lr_balanced_accuracy, lr_eval_metrics=balanced_accuracy(y_test,y_pred_lr)\n",
    "print(\"balanced accuracy:\", lr_balanced_accuracy)\n",
    "\n",
    "model_accs['logistic regression'] = [lr_test_accuracy,lr_balanced_accuracy,lr_eval_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "balanced accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(150,100,50), activation='relu')\n",
    "mlp_model.fit(X_test, y_test)\n",
    "\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "mlp_test_accuracy = metrics.accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy: \", mlp_test_accuracy)\n",
    "\n",
    "mlp_balanced_accuracy, mlp_eval_metrics=balanced_accuracy(y_test,y_pred_mlp)\n",
    "print(\"balanced accuracy:\", mlp_balanced_accuracy)\n",
    "\n",
    "model_accs['neural network'] = [mlp_test_accuracy,mlp_balanced_accuracy,mlp_eval_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9108108108108108\n",
      "balanced accuracy: 0.9148102310231023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linds\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "y_pred_rfc = rfc_model.predict(X_test)\n",
    "\n",
    "rfc_test_accuracy = metrics.accuracy_score(y_test, y_pred_rfc)\n",
    "print(\"Accuracy: \", rfc_test_accuracy)\n",
    "\n",
    "rfc_balanced_accuracy, rfc_eval_metrics=balanced_accuracy(y_test,y_pred_rfc)\n",
    "print(\"balanced accuracy:\", rfc_balanced_accuracy)\n",
    "\n",
    "model_accs['random forest'] = [rfc_test_accuracy,rfc_balanced_accuracy,rfc_eval_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9027027027027027\n",
      "balanced accuracy: 0.904879773691655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "ada_test_accuracy = metrics.accuracy_score(y_test, y_pred_ada)\n",
    "print(\"Accuracy: \", ada_test_accuracy)\n",
    "\n",
    "ada_balanced_accuracy, ada_eval_metrics=balanced_accuracy(y_test,y_pred_ada)\n",
    "print(\"balanced accuracy:\", ada_balanced_accuracy)\n",
    "\n",
    "model_accs['adaboost'] = [ada_test_accuracy,ada_balanced_accuracy,ada_eval_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9162162162162162\n",
      "balanced accuracy: 0.9197607260726073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(random_state=0)\n",
    "gbc_model.fit(X_train, y_train)\n",
    "y_pred_gbc = gbc_model.predict(X_test)\n",
    "\n",
    "gbc_test_accuracy = metrics.accuracy_score(y_test, y_pred_gbc)\n",
    "print(\"Accuracy: \", gbc_test_accuracy)\n",
    "\n",
    "gbc_balanced_accuracy, gbc_eval_metrics=balanced_accuracy(y_test,y_pred_gbc)\n",
    "print(\"balanced accuracy:\", gbc_balanced_accuracy)\n",
    "\n",
    "model_accs['gradient boost'] = [gbc_test_accuracy,gbc_balanced_accuracy,gbc_eval_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn :  0.9135135135135135\n",
      "decision tree :  0.8513513513513513\n",
      "svm :  0.9054054054054054\n",
      "logistic regression :  0.7783783783783784\n",
      "neural network :  1.0\n",
      "random forest :  0.9108108108108108\n",
      "adaboost :  0.9027027027027027\n",
      "gradient boost :  0.9162162162162162\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "accs = []\n",
    "for model, accuracy in model_accs.items():\n",
    "    print(model, ': ', accuracy[0])\n",
    "    models.append(model)\n",
    "    accs.append(accuracy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['knn', 'decision tree', 'svm', 'logistic regression', 'neural network', 'random forest', 'adaboost', 'gradient boost']\n",
      "[0.9135135135135135, 0.8513513513513513, 0.9054054054054054, 0.7783783783783784, 1.0, 0.9108108108108108, 0.9027027027027027, 0.9162162162162162]\n"
     ]
    }
   ],
   "source": [
    "print((models))\n",
    "print((accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(models, accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             measure         knn  decision tree         svm  \\\n",
      "0      test accuracy    0.913514       0.851351    0.905405   \n",
      "1  balanced accuracy    0.905764       0.847330    0.903347   \n",
      "2                 tp  200.000000     180.000000  187.000000   \n",
      "3                 tn  138.000000     135.000000  148.000000   \n",
      "4                 fp   30.000000      33.000000   20.000000   \n",
      "5                 fn    2.000000      22.000000   15.000000   \n",
      "\n",
      "   logistic regression  neural network  random forest    adaboost  \\\n",
      "0             0.778378             1.0       0.910811    0.902703   \n",
      "1             0.775489             1.0       0.914810    0.904880   \n",
      "2           163.000000           202.0     176.000000  178.000000   \n",
      "3           125.000000           168.0     161.000000  156.000000   \n",
      "4            43.000000             0.0       7.000000   12.000000   \n",
      "5            39.000000             0.0      26.000000   24.000000   \n",
      "\n",
      "   gradient boost  \n",
      "0        0.916216  \n",
      "1        0.919761  \n",
      "2      178.000000  \n",
      "3      161.000000  \n",
      "4        7.000000  \n",
      "5       24.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df= pd.DataFrame()\n",
    "df[\"measure\"]= [\"test accuracy\", \"balanced accuracy\", \"tp\", \"tn\", \"fp\", \"fn\"]\n",
    "for model, accuracy in model_accs.items():\n",
    "    df[model]= [accuracy[0],accuracy[1],accuracy[2][0],accuracy[2][1],accuracy[2][2],accuracy[2][3]]\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sachi TODO:\n",
    "\n",
    "- For random forest classifier and decision tree, plot the accuracy of the model as maximum tree depth increases (start at depth 1 and go up to 30) hint use a for loop\n",
    "- Do the same thing for KNN plot accuracy as number of neighbors increases\n",
    "- Start by plotting validation curve for KNN then try with other models\n",
    "- Try to plot ROC curves\n",
    "- Calculate balanced accuracy *****\n",
    "- Calculate precision\n",
    "- Calculate F1\n",
    "- True negative, false negative, true positive, false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
